{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35e460a",
   "metadata": {},
   "source": [
    "Diabetic Retinopathy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02b8d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and setup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b488a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " diagnosis\n",
      "0    1434\n",
      "1     300\n",
      "2     808\n",
      "3     154\n",
      "4     234\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === 1. Load and Visualize Class Distribution ===\n",
    "df = pd.read_csv(r\"C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\data\\train.csv\")\n",
    "class_counts = df['diagnosis'].value_counts().sort_index()\n",
    "\n",
    "print('Class Distribution:\\n', class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00224dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(class_counts.index, class_counts.values, tick_label=[f\"Class {i}\" for i in class_counts.index])\n",
    "plt.title(\"Diabetic Retinopathy Class Distribution\")\n",
    "plt.xlabel(\"Severity Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.savefig(\"../visuals/class_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d578e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " id_code      0\n",
      "diagnosis    0\n",
      "dtype: int64\n",
      "Duplicate entries:\n",
      " Empty DataFrame\n",
      "Columns: [id_code, diagnosis]\n",
      "Index: []\n",
      "Unique diagnosis values: [2 1 4 0 3]\n"
     ]
    }
   ],
   "source": [
    "#Missing or Corrupted Entries\n",
    "#Check for missing values, duplicates, and stray formatting.\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check for duplicate IDs\n",
    "duplicates = df[df['id_code'].duplicated()]\n",
    "print(\"Duplicate entries:\\n\", duplicates)\n",
    "\n",
    "# Check for stray spaces or formatting issues\n",
    "df['id_code'] = df['id_code'].str.strip()\n",
    "print(\"Unique diagnosis values:\", df['diagnosis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0363fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Train/Validation Split ===\n",
    "X = df['id_code']\n",
    "y = df['diagnosis']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = pd.DataFrame({'id_code': X_train, 'diagnosis': y_train})\n",
    "val_df = pd.DataFrame({'id_code': X_val, 'diagnosis': y_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1686b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Compute Class Weights ===\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88085d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Define Transforms ===\n",
    "minority_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "majority_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transform_dict = {\n",
    "    0: majority_transform,\n",
    "    1: minority_transform,\n",
    "    2: majority_transform,\n",
    "    3: minority_transform,\n",
    "    4: minority_transform\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6663bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Custom Dataset ===\n",
    "class DRDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform_dict):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform_dict = transform_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.loc[idx, 'id_code']\n",
    "        label = self.df.loc[idx, 'diagnosis']\n",
    "        img_path = os.path.join(self.root_dir, f\"{img_id}.png\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        transform = self.transform_dict.get(label, transforms.ToTensor())\n",
    "        image = transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925ceff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. DataLoaders ===\n",
    "train_dataset = DRDataset(train_df, root_dir='../data/train_images', transform_dict=transform_dict)\n",
    "val_dataset = DRDataset(val_df, root_dir='../data/train_images', transform_dict=transform_dict)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3264bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7. Model Definition ===\n",
    "class DRClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DRClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),  # Output: (batch_size, 64, 1, 1)\n",
    "            nn.Flatten(),                  # Output: (batch_size, 64)\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 5)\n",
    "     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c7f1930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 74/74 [07:45<00:00,  6.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 119.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 74/74 [07:06<00:00,  5.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 118.6789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 74/74 [07:12<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 116.4245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 74/74 [07:20<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 112.5843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 74/74 [07:01<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 110.3583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 74/74 [06:40<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 108.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 74/74 [07:01<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 105.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 74/74 [06:56<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 101.9503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 74/74 [06:56<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 99.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 74/74 [07:00<00:00,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 96.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 8. Training Loop ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DRClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d54fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5836\n",
      "Confusion Matrix:\n",
      " [[201  50  11  23   2]\n",
      " [  0  47   5   8   0]\n",
      " [  4  58  86  13   0]\n",
      " [  0  19   4   8   0]\n",
      " [  2  28   5  12   0]]\n"
     ]
    }
   ],
   "source": [
    "# === 9. Validation accuracy and confusion matrix===\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a901dd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/74 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 74/74 [06:54<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 94.2270, Val Loss: 22.1356\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 74/74 [07:14<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 90.0477, Val Loss: 21.9548\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 74/74 [07:13<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 88.9504, Val Loss: 21.0224\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 74/74 [06:47<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 85.7209, Val Loss: 19.6324\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 74/74 [09:05<00:00,  7.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 83.6556, Val Loss: 19.1881\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 74/74 [09:36<00:00,  7.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 82.6020, Val Loss: 18.7077\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 74/74 [09:20<00:00,  7.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 79.1931, Val Loss: 19.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 74/74 [09:39<00:00,  7.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 80.4495, Val Loss: 18.5941\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 74/74 [09:28<00:00,  7.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 76.6198, Val Loss: 18.3162\n",
      "✅ Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 74/74 [09:37<00:00,  7.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 76.5364, Val Loss: 17.8699\n",
      "✅ Saved best model\n"
     ]
    }
   ],
   "source": [
    "# === 10. Save Best Model ===\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # === Validation Pass ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # === Save Best Model ===\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"✅ Saved best model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4131924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7715\n",
      "Cohen’s Kappa: 0.6479\n",
      "ROC–AUC: 0.9220\n"
     ]
    }
   ],
   "source": [
    "# === 11. Additional Metrics: F1-score, Cohen’s Kappa, ROC–AUC ===\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)  # shape: [batch_size, 5]\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_outputs.extend(outputs.cpu().numpy())  # store raw logits\n",
    "\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, roc_auc_score\n",
    "\n",
    "# After collecting all_preds and all_labels\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "\n",
    "# For ROC–AUC, you need probabilities and one-hot labels\n",
    "from sklearn.preprocessing import label_binarize\n",
    "y_true_bin = label_binarize(all_labels, classes=[0,1,2,3,4])\n",
    "all_outputs_np = np.array(all_outputs)  # Convert list of arrays to single ndarray\n",
    "y_pred_prob = torch.softmax(torch.from_numpy(all_outputs_np), dim=1).numpy()\n",
    "\n",
    "roc_auc = roc_auc_score(y_true_bin, y_pred_prob, average='macro', multi_class='ovr')\n",
    "\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"Cohen’s Kappa: {kappa:.4f}\")\n",
    "print(f\"ROC–AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0eae5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 12. Model Explainability with Grad-CAM ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e3ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_62cc7ddb53b6.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_bfd5c0e55420.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_6e1db8711879.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_bdc6c60e9133.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_300305ce82d2.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_62ecdc90dd42.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_ba0107fb1bfd.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_61ac9b0dc6b9.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_d9a475dfe59a.png\n",
      "✅ Saved: C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\\gradcam_81d79d53ed7b.png\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Define Model ===\n",
    "class DRClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DRClassifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model and Grad-CAM\n",
    "model = DRClassifier().to(device)\n",
    "cam_extractor = GradCAM(model, target_layer=model.conv[3])  # second Conv2d layer\n",
    "\n",
    "# === Define Grad-CAM Generator Function ===\n",
    "def generate_gradcam(\n",
    "    model, cam_extractor, val_df, base_img_dir, output_dir=\"visuals\", \n",
    "    transform=None, device=\"cpu\", num_samples=5\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    if transform is None:\n",
    "        transform = Compose([Resize((128, 128)), ToTensor()])\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        sample_id = val_df.iloc[i]['id_code']\n",
    "        sample_path = os.path.join(base_img_dir, f\"{sample_id}.png\")\n",
    "        \n",
    "        if not os.path.exists(sample_path):\n",
    "            print(f\"❌ Missing image: {sample_path}\")\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(sample_path).convert('RGB')\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        output = model(input_tensor)\n",
    "        pred_class = output.argmax(dim=1).item()\n",
    "        \n",
    "        activation_map = cam_extractor(pred_class, output)\n",
    "        original = to_pil_image(input_tensor.squeeze().cpu())\n",
    "        heatmap = to_pil_image(activation_map[0].cpu(), mode='F')\n",
    "        overlay = overlay_mask(original, heatmap, alpha=0.5)\n",
    "        \n",
    "        save_path = os.path.join(output_dir, f\"gradcam_{sample_id}.png\")\n",
    "        overlay.save(save_path)\n",
    "        print(f\"✅ Saved: {save_path}\")\n",
    "\n",
    "# === Run Grad-CAM on Multiple Samples ===\n",
    "generate_gradcam(\n",
    "    model=model,\n",
    "    cam_extractor=cam_extractor,\n",
    "    val_df=val_df,\n",
    "    base_img_dir=r\"C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\data\\train_images\",\n",
    "    output_dir=r\"C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\",\n",
    "    device=device,\n",
    "    num_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a32276af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SHAP saved: shap_62cc7ddb53b6.png\n",
      "✅ SHAP saved: shap_bfd5c0e55420.png\n",
      "✅ SHAP saved: shap_6e1db8711879.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === SHAP Integration for CNN (GradientExplainer) ===\n",
    "import shap\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# === 1. Define transform (same as training) ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# === 2. Load sample images from validation set ===\n",
    "base_dir = r\"C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\data\\train_images\"\n",
    "sample_images = []\n",
    "sample_ids = []\n",
    "\n",
    "for i in range(5):\n",
    "    sample_id = val_df.iloc[i]['id_code']\n",
    "    sample_path = os.path.join(base_dir, f\"{sample_id}.png\")\n",
    "    if os.path.exists(sample_path):\n",
    "        img = Image.open(sample_path).convert('RGB')\n",
    "        tensor = transform(img).unsqueeze(0)\n",
    "        sample_images.append(tensor)\n",
    "        sample_ids.append(sample_id)\n",
    "\n",
    "# === 3. Stack into batch and enable gradients ===\n",
    "input_batch = torch.cat(sample_images).to(device)\n",
    "input_batch.requires_grad_()\n",
    "\n",
    "# === 4. Wrap model in nn.Module for SHAP ===\n",
    "class SHAPWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "wrapped_model = SHAPWrapper(model)\n",
    "model.eval()\n",
    "\n",
    "# === 5. Run SHAP GradientExplainer ===\n",
    "explainer = shap.GradientExplainer(wrapped_model, input_batch)\n",
    "shap_values = explainer.shap_values(input_batch)\n",
    "\n",
    "# === 6. Save SHAP Visuals ===\n",
    "output_dir = r\"C:\\Users\\Jacy Heather\\Desktop\\ML or AI\\Diabetic Retinopathy Classifier\\visuals\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "num_valid = len(shap_values[0])\n",
    "for i in range(num_valid):\n",
    "    img_np = input_batch[i].detach().cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "    shap_img = shap_values[0][i].transpose(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    shap.image_plot([shap_img], img_np, show=False)\n",
    "    plt.savefig(os.path.join(output_dir, f\"shap_{sample_ids[i]}.png\"))\n",
    "    plt.close()\n",
    "    print(f\"✅ SHAP saved: shap_{sample_ids[i]}.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
